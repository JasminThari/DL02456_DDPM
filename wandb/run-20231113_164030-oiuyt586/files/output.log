
0
Traceback (most recent call last):
  File "/work3/s204148/DL02456_DDPM/DDPM.py", line 188, in <module>
    train(args)
  File "/work3/s204148/DL02456_DDPM/DDPM.py", line 140, in train
    sampled_images = diffusion.sampling(model, num_img=6)
  File "/work3/s204148/DL02456_DDPM/DDPM.py", line 111, in sampling
    predicted_noise = model(x, t)
  File "/work3/s204148/DL02456_DDPM/venv3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work3/s204148/DL02456_DDPM/modules.py", line 169, in forward
    x2 = self.sa1(x2)
  File "/work3/s204148/DL02456_DDPM/venv3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work3/s204148/DL02456_DDPM/modules.py", line 50, in forward
    x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)
RuntimeError: shape '[-1, 128, 1024]' is invalid for input of size 150528